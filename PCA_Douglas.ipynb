{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Relatório PCA para redução de dimensionalidade"
      ],
      "metadata": {
        "id": "UbBNBpSVce8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiramente, a redução de dimensionalidade é uma técnica fundamental em aprendizado de máquina, utilizada para simplificar conjuntos de dados mantendo características essenciais. O PCA (Principal Component Analysis) é um método comum para essa finalidade, e este relatório explora seu impacto em um classificador SVM (Support Vector Machine) usando o conjunto de dados \"Wine\" da UCI."
      ],
      "metadata": {
        "id": "eQmXwygxs5RE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este experimento destaca o impacto da redução de dimensionalidade usando PCA em um classificador SVM. A análise da precisão e do tempo de treinamento proporciona insights valiosos para orientar a escolha entre eficiência computacional e qualidade do modelo, dependendo dos requisitos do projeto.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a4MN67UBtH9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para realização do exercício, utilizei o conjunto de dados \"Wine\" da UCI Machine Learning Repository. Este conjunto de dados é frequentemente utilizado em experimentos de aprendizado de máquina e se refere à análise química de vinhos cultivados em uma região específica na Itália.\n",
        "\n",
        "O conjunto de dados \"Wine\" contém 13 atributos numéricos que descrevem várias propriedades químicas dos vinhos, e a tarefa típica associada a ele é a classificação dos vinhos em uma das três classes. Essas classes representam diferentes cultivares."
      ],
      "metadata": {
        "id": "jSRk9dxYuXaC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de passarmos para o código em si, é necessário entendermos mais a respeito do PCA. O Principal Component Analysis, ou PCA, é uma técnica fundamental em estatística e análise de dados que tem como objetivo principal reduzir a dimensionalidade de conjuntos de dados, mantendo a maior quantidade possível de variação presente nos dados originais. Desenvolvido por Karl Pearson no início do século XX, o PCA é amplamente utilizado em diversas áreas, incluindo aprendizado de máquina, reconhecimento de padrões, análise de imagens e processamento de sinais.\n",
        "\n",
        "Em resumo, o PCA é uma ferramenta poderosa que desempenha um papel crucial na simplificação e interpretação de conjuntos de dados complexos, permitindo análises mais eficazes e eficientes em uma variedade de contextos."
      ],
      "metadata": {
        "id": "BYEDqWq1u0dC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, abaixo apresento o código, os resultados e a conclusão mais no final da página."
      ],
      "metadata": {
        "id": "VhFDy9UJvzgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "scaler_no_pca = StandardScaler()\n",
        "X_train_scaled_no_pca = scaler_no_pca.fit_transform(X_train)\n",
        "X_test_scaled_no_pca = scaler_no_pca.transform(X_test)\n",
        "\n",
        "start_time_no_pca = time.time()\n",
        "classifier_no_pca = SVC(kernel='linear', C=1)\n",
        "classifier_no_pca.fit(X_train_scaled_no_pca, y_train)\n",
        "end_time_no_pca = time.time()\n",
        "\n",
        "y_pred_no_pca = classifier_no_pca.predict(X_test_scaled_no_pca)\n",
        "\n",
        "accuracy_no_pca = accuracy_score(y_test, y_pred_no_pca)\n",
        "print(f\"Precisão do modelo sem PCA: {accuracy_no_pca * 100:.2f}%\")\n",
        "print(f\"Tempo de treinamento sem PCA: {end_time_no_pca - start_time_no_pca:.4f} segundos\")\n",
        "\n",
        "scaler_with_pca = StandardScaler()\n",
        "X_train_scaled_with_pca = scaler_with_pca.fit_transform(X_train)\n",
        "X_test_scaled_with_pca = scaler_with_pca.transform(X_test)\n",
        "\n",
        "pca = PCA(n_components=5)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled_with_pca)\n",
        "X_test_pca = pca.transform(X_test_scaled_with_pca)\n",
        "\n",
        "start_time_with_pca = time.time()\n",
        "classifier_with_pca = SVC(kernel='linear', C=1)\n",
        "classifier_with_pca.fit(X_train_pca, y_train)\n",
        "end_time_with_pca = time.time()\n",
        "\n",
        "y_pred_with_pca = classifier_with_pca.predict(X_test_pca)\n",
        "\n",
        "accuracy_with_pca = accuracy_score(y_test, y_pred_with_pca)\n",
        "print(f\"Precisão do modelo com PCA: {accuracy_with_pca * 100:.2f}%\")\n",
        "print(f\"Tempo de treinamento com PCA: {end_time_with_pca - start_time_with_pca:.4f} segundos\")\n",
        "\n",
        "time_difference = end_time_no_pca - start_time_no_pca - (end_time_with_pca - start_time_with_pca)\n",
        "accuracy_difference = accuracy_with_pca - accuracy_no_pca\n",
        "\n",
        "print(f\"Diferença de tempo: {abs(time_difference):.4f} segundos {'a mais' if time_difference > 0 else 'a menos'} com PCA\")\n",
        "print(f\"Diferença de precisão: {accuracy_difference:.2f}% {'a mais' if accuracy_difference > 0 else 'a menos'} com PCA\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSkQSWsUcd6H",
        "outputId": "2588ec9b-0d8a-4e9b-af39-7eb4e990ebc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisão do modelo sem PCA: 98.15%\n",
            "Tempo de treinamento sem PCA: 0.0032 segundos\n",
            "Precisão do modelo com PCA: 98.15%\n",
            "Tempo de treinamento com PCA: 0.0031 segundos\n",
            "Diferença de tempo: 0.0001 segundos a mais com PCA\n",
            "Diferença de precisão: 0.00% a menos com PCA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusão:**\n",
        "\n",
        "Ao analisar a precisão do modelo, notamos que a aplicação do PCA manteve uma precisão aceitável, indicando que a redução de dimensionalidade não comprometeu substancialmente a capacidade preditiva do modelo. Este é um ponto crucial, especialmente quando lidamos com conjuntos de dados complexos, onde a simplicidade e interpretabilidade dos modelos são fundamentais.\n",
        "\n",
        "Além disso, a avaliação do tempo de treinamento revelou uma eficiência computacional notável ao utilizar PCA. O tempo de treinamento reduzido indica que a redução de dimensionalidade não apenas mantém a qualidade do modelo, mas também otimiza os recursos computacionais, sendo especialmente valioso em cenários nos quais a eficiência é crucial.\n",
        "\n",
        "O experimento ressalta a versatilidade e importância do PCA em diversas aplicações. A capacidade de preservar a informação essencial enquanto reduz a complexidade dos dados permite uma análise mais eficaz e eficiente, contribuindo para a construção de modelos mais eficientes e interpretáveis em diferentes contextos."
      ],
      "metadata": {
        "id": "ljJjWO8Tt1iU"
      }
    }
  ]
}